---
title: "Computational scaling of eclairs data whitening"
subtitle: 'Estimate of covariance using low rank and shrinkage'
author: "Developed by [Gabriel Hoffman](http://gabrielhoffman.github.io/)"
date: "Run on `r Sys.time()`"
documentclass: article
output: 
  html_document:
  toc: true
  smart: false
vignette: >
  %\VignetteIndexEntry{Computational scaling of data whitening}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  %\usepackage[utf8]{inputenc}
---



<!--- 

cd /hpc/users/hoffmg01/work/decorrelate_analysis

R
system("git pull")
rmarkdown::render("computational_scaling.Rmd");




https://hoffmg01.hpc.mssm.edu/decorrelate_analysis/computational_scaling.html

--->



```{r setup, include=FALSE}
library(data.table)
library(lubridate)
library(tidyverse)
library(cowplot)
library(knitr)
library(kableExtra)
library(RhpcBLASctl)
library(clusterGeneration)

knitr::opts_chunk$set(
	eval = TRUE,
  echo = FALSE,
  warning=FALSE,
  message=FALSE,
  error = FALSE,
  tidy = FALSE,
  dev = c("png", "pdf"),
  cache = TRUE)
```

```{r define.function}
eval_runTime = function(df_values, naive.maxp=10000, ncores=12){

	omp_set_num_threads(ncores)

	df_time = lapply( 1:nrow(df_values), function(i){

		n = df_values$n[i]
		p = df_values$p[i]
		k = df_values$k[i]

		message("\r", p, '       ')

		# Y = matrnorm(n,p)

		if( n < p ){ 
			Sigma = genPositiveDefMat(n, ratioLambda=200)$Sigma
			Y = t(rmvnorm(p, mu=rep(0, n), Sigma))
		}else{

			Sigma = genPositiveDefMat(p, ratioLambda=200)$Sigma
			Y = rmvnorm(n, mu=rep(0, p), Sigma)
		}
		rm(Sigma)

		lambda <- 1e-1

		# full SVD
		res_decor = system.time({
			ecl <- eclairs(Y, compute="covariance", lambda=lambda)
			Z1 <- decorrelate(Y, ecl)
		})
		rm(Z1)
		time_decorrelate = res_decor[c(1,3)]

		# partial SVD
		res_partial = system.time({
			ecl <- eclairs(Y, compute="covariance", lambda=lambda, k=k)
			Z1 <- decorrelate(Y, ecl)
		})
		rm(Z1)
		time_decorrelate_partial = res_partial[c(1,3)]

		# naive
		if(p <= naive.maxp){
			res2 = system.time({
				# C <- cov(Y) 
				# Sigma <- C*(1-lambda) + diag(lambda*ecl$nu, p)
				W = whiteningMatrix(cov(Y)*(1-lambda) + diag(lambda*ecl$nu, p), method="ZCA")
				Z2 <- tcrossprod(Y, W)
				# Z2 = whiten(Y)
			})
			rm(W)
			rm(Z2)
			time_naive = res2[c(1,3)]

			# Z1 and Z2 are identical to machine precision
			# range(Z1 - Z2)

		}else{
			time_naive = NA
		}
		rm(Y)

		data.frame(n = n, p = p, k = k, 
			decorrelate.cpu = time_decorrelate[1],
			decorrelate.wall = time_decorrelate[2], 
			low_rank.cpu = time_decorrelate_partial[1],
			low_rank.wall = time_decorrelate_partial[2],
			naive.cpu = time_naive[1],
			naive.wall= time_naive[2])
	})
	df_time = do.call(rbind, df_time)
	df_time
}

fit_curves = function( df_time, curves ){
	# predict based on curves
	fit1 = lm(curves[[1]], df_time)
	fit2 = lm(curves[[2]], df_time)
	fit3 = lm(curves[[3]], df_time)

	p_max = max(df_time$p)
	n_max = max(df_time$n)

	df_p = data.table(p=seq(100, p_max, length.out=1000),
										n=seq(100, n_max, length.out=1000))

	df_p$decorrelate = predict(fit1, df_p)
	df_p$naive = predict(fit2, df_p)
	df_p$low.rank = predict(fit3, df_p)
	df_melt_p = melt(df_p, id.vars=c('p', 'n') )
	df_melt_p$variable = factor(df_melt_p$variable, c("naive", "decorrelate", 'low.rank'))

	# directly observed times
	df_melt = reshape2::melt(df_time, id.vars=c("p", 'n', 'k'))
	df_melt$variable = factor(df_melt$variable, c("naive", "decorrelate", 'low.rank'))

	list(df_observed = df_melt, df_smoothed = df_melt_p)
}
```


```{r simulate.data}
library(decorrelate)
library(Matrix)
library(Rfast)
library(ggplot2)
library(cowplot)
library(whitening)

# due to parallel processing, curves are not exactly cubic and linear
# values = as.integer(sort(c(	seq(500, 30000, length.out=100))))
values = as.integer(sort(c(	seq(500, 10000, length.out=6))))

df_values = data.frame(n = 5000, p = values, k = 50)

df_time = eval_runTime( df_values, 10000, ncores=12 )

res = df_time %>%
	as_tibble %>%
	pivot_longer(cols = c("decorrelate.cpu", "decorrelate.wall", "low_rank.cpu", "low_rank.wall", "naive.cpu", "naive.wall")) %>%
	mutate(Method =  gsub("^(.*)\\.(.*)$", "\\1", name)) %>%
	mutate(Measure =  gsub("^(.*)\\.(.*)$", "\\2", name)) %>%
	dplyr::select(-name)
```


```{r plot.results.wall, cache=FALSE, fig.height=6, fig.width=12}
# Wall time
fig = res %>% 
	filter(Measure == "wall") %>%
	ggplot(aes(p, value, color=Method)) + 
		geom_point() + 
		theme_classic(16) + 
		theme(aspect.ratio=1, plot.title = element_text(hjust = 0.5), legend.position="bottom") + 
		xlab("Number of features") + 
		ylab("Wall Time (seconds)") + 
		# geom_line(data=res$df_smoothed, aes(p, value, color=variable)) + 
		scale_color_manual(name="Method", values = c("green4", "#E41A1C", "#9f1214")) + 
		ggtitle("n = 5000")

ymax.naive = res %>% 
	filter(Measure == "wall", Method == "naive") %>%
	pull(value) %>%
	max(na.rm=TRUE)

ymax.d = res %>% 
	filter(Measure == "wall", Method == "decorrelate") %>%
	pull(value) %>%
	max(na.rm=TRUE)

fig1 = fig + 
	scale_y_continuous(expand=c(0,1), limits=c(0, ymax)) + 
	scale_x_continuous(limits=c(0, 20000), expand=c(0,0))
fig2 = fig + 
	scale_y_continuous(expand=c(0,.5), limits=c(0, ymax.d))) + 
	scale_x_continuous(expand=c(0,0))
fig3 = fig + scale_x_log10() + 
	scale_y_log10() + xlab(bquote(Number~of~features~(log[10]))) + 
ylab(bquote(Time~(log[10]~seconds)))

plot_grid(fig1, fig2, fig3, nrow=1)
```

```{r plot.results.wall, cache=FALSE, fig.height=6, fig.width=12}
# CPU time
fig = res %>% 
	filter(Measure == "cpu") %>%
	ggplot(aes(p, value, color=Method)) + 
		geom_point() + 
		theme_classic(16) + 
		theme(aspect.ratio=1, plot.title = element_text(hjust = 0.5), legend.position="bottom") + 
		xlab("Number of features") + 
		ylab("CPU Time (seconds)") + 
		# geom_line(data=res$df_smoothed, aes(p, value, color=variable)) + 
		scale_color_manual(name="Method", values = c("green4", "#E41A1C", "#9f1214")) + 
		ggtitle("n = 5000")

ymax.naive = res %>% 
	filter(Measure == "cpu", Method == "naive") %>%
	pull(value) %>%
	max(na.rm=TRUE)

ymax.d = res %>% 
	filter(Measure == "cpu", Method == "decorrelate") %>%
	pull(value) %>%
	max(na.rm=TRUE)

fig1 = fig + 
	scale_y_continuous(expand=c(0,1), limits=c(0, ymax)) + 
	scale_x_continuous(limits=c(0, 20000), expand=c(0,0))
fig2 = fig + 
	scale_y_continuous(expand=c(0,.5), limits=c(0, ymax.d))) + 
	scale_x_continuous(expand=c(0,0))
fig3 = fig + scale_x_log10() + 
	scale_y_log10() + xlab(bquote(Number~of~features~(log[10]))) + 
ylab(bquote(Time~(log[10]~seconds)))

plot_grid(fig1, fig2, fig3, nrow=1)
```


```{r exit, cache=FALSE}
knitr::knit_exit()
```















```{r plot.results, cache=FALSE, fig.height=6, fig.width=12}
curves = c(decorrelate ~ 0 + p + I(p^2),
	naive ~ 0 + I(p^2) + I(p^3),
	low.rank ~ 0 + p)

res = fit_curves( df_time, curves)

fig = ggplot(res$df_observed, aes(p, value, color=variable)) + 
	geom_point() + 
	theme_classic(16) + 
	theme(aspect.ratio=1, plot.title = element_text(hjust = 0.5), legend.position="bottom") + 
	xlab("Number of features") + 
	ylab("Time (seconds)") + 
	geom_line(data=res$df_smoothed, aes(p, value, color=variable)) + 
	scale_color_manual(name="Method", values = c("green4", "#E41A1C", "#9f1214")) + 
	ggtitle("n = 5000")


fig1 = fig + scale_y_continuous(expand=c(0,1), limits=c(0, max(df_time$naive, na.rm=TRUE))) + scale_x_continuous(limits=c(0, 20000), expand=c(0,0))
fig2 = fig + scale_y_continuous(expand=c(0,.5), limits=c(0, with(df_time, max(decorrelate, low.rank)))) + scale_x_continuous(expand=c(0,0))
fig3 = fig + scale_x_log10() + scale_y_log10() + xlab(bquote(Number~of~features~(log[10]))) + ylab(bquote(Time~(log[10]~seconds)))

plot_grid(fig1, fig2, fig3, nrow=1)
```











```{r test, eval=FALSE}
n = 5000
p = 10000

library(clusterGeneration)

Sigma = genPositiveDefMat(n, ratioLambda=200)$Sigma
Y = t(rmvnorm(p, mu=rep(0, n), Sigma))



lambda <- 1e-1

# full SVD
system.time({
	ecl <- eclairs(Y, compute="covariance", lambda=lambda)
	# Z1 <- decorrelate(Y, ecl)
})

# partial SVD
system.time({
	ecl <- eclairs(Y, compute="covariance", lambda=lambda, k=k)
	# Z1 <- decorrelate(Y, ecl)
})

# full SVD
system.time({ecl1 <- eclairs(Y, compute="covariance", lambda=lambda)})
system.time({ecl2 <- eclairs(Y, compute="covariance", lambda=lambda, k=k)})

system.time({	Z1 <- decorrelate(Y, ecl1)})
system.time({	Z1 <- decorrelate(Y, ecl2)})

system.time(svd(Y))
system.time(irlba::irlba(Y, 200))
system.time(PRIMME::svds(Y, 200, isreal=TRUE))




```




<!-- Run time at r max(values) features: -->

<!--
```{r time.table, cache=FALSE, eval=FALSE}
df2 = df_melt_p[p %in% c(2000, 1000000),]
df2$RunTime = seconds_to_period( round(df2$value, 0))

df2 %>% rename(Method = variable) %>% 
	select(Method,p, RunTime) %>% 
	kable(caption="Compare run times") %>% kable_styling(full_width=FALSE) 
```
-->

<!-- 
This is a speed up of r format(max(df2$value) / min(df2$value), big.mark=',')

-->




# Increasing sample size
```{r increase.n}
p = 5000

values = c(seq(200, 2*p, length.out=100),
				seq( 2.1*p, 50000, length.out=50))
values =  as.integer(sort(values))

df_values = data.frame(n = values, p=p, k = 20)

df_time2 = eval_runTime( df_values, p+1  )

curves = c(decorrelate ~ I(n<7200) + I((n<7200)*n^2)+ n,
	naive ~ n,
	low.rank ~ n + I(n^2))

res2 = fit_curves( df_time2, curves)
```

```{r plot.results.n, cache=FALSE, fig.height=6, fig.width=12}
fig = ggplot(res2$df_observed, aes(n, value, color=variable)) + geom_point() + theme_classic(16) + theme(aspect.ratio=1, plot.title = element_text(hjust = 0.5), legend.position="bottom") + xlab("Number of samples") + ylab("Time in seconds") + geom_line(data=res2$df_smoothed, aes(n, value, color=variable)) + scale_color_manual(name="Method", values = c("red", "blue", "green")) + ggtitle("p = 5000") + geom_vline(xintercept=p, linetype="dashed", colr="grey40")

fig1 = fig + scale_y_continuous(expand=c(0,0), limits=c(0, max(df_time2$decorrelate, na.rm=TRUE))) + scale_x_continuous(limits=c(0, 3*p), expand=c(0,0))
fig2 = fig + scale_y_continuous(expand=c(0,0), limits=c(0, max(df_time2$naive, na.rm=TRUE))) + scale_x_continuous(limits=c(0, 20000), expand=c(0,0))
fig3 = fig + scale_x_log10() + scale_y_log10() + scale_x_log10() + scale_y_log10() + xlab(bquote(Number~of~samples~(log[10]))) + ylab(bquote(Time~(log[10]~seconds)))

plot_grid(fig1, fig2, fig3, nrow=1)
```

pdf("test.pdf", height=6, width=12)
plot_grid(fig1, fig2, fig3, nrow=1)
dev.off()




















