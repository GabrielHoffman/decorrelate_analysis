
cd /sc/arion/projects/CommonMind/hoffman/ldref
R

suppressPackageStartupMessages({
library(VariantAnnotation)
library(GenomicRanges)
library(rtracklayer)
library(decorrelate)
library(Rfast)
library(ggplot2)
library(CovTools)
library(ShrinkCovMat)
library(corpcor)
library(Matrix)
library(survival)
})

# from: /Users/gabrielhoffman/workspace/repos/eval_methods/decorrelate
# norm of matrix compared to identity,
# This is the root mean squared error of the off diagonal entries
normCov = function(Sigma){

  if( length(Sigma) == 1)
    if( is.na(Sigma) ) return(NA)
  # base::norm(Sigma - diag(1, nrow(Sigma)), "F")^2 / length(Sigma)

  mse = mean((Sigma-diag(1, nrow(Sigma)))^2)
  sqrt(mse)
}


file = "/sc/arion/projects/data-ark/Public_Unrestricted/1000G/phase3/release_2013502/integrated_call_samples_v3.20130502.ALL.panel"
infoAll = read.table(file, header=TRUE)
infoAll$sample = paste(infoAll$sample, infoAll$sample, sep="_")


# "Touloumis", "Schafer", "LW"
df_grid = expand.grid(chrom=21:22, method = c("eb", "0.01", "Schafer"), super_pop="EUR", pop.train="CEU", stringsAsFactors=FALSE)


maf = function(x){
	af = sum(x) / (2*length(x))
	min(af, 1-af)
}


df = lapply(1:nrow(df_grid), function(i){

	message(i)

	# subset info to this super pop
	idx = which(infoAll$super_pop == df_grid$super_pop[i])
	info = infoAll[idx,]

	# read in genome-blocks for this population
	file = paste0("ldetect-data/", df_grid$super_pop[i], "/fourier_ls-all_mod.bed")
	gr = import(file, format="bed")
	seqlevelsStyle(gr) = "NCBI"

	# subset Granges for this chrom
	gr_chr = gr[seqnames(gr) == df_grid$chrom[i]]

	df = lapply(seq(length(gr_chr)), function(k){
		# Read data in range
		vcf.file = paste0("filter/", df_grid$super_pop[i], ".chr",df_grid$chrom[i], ".vcf.gz")
		res = readVcf( vcf.file, genome = "GRCh37", param = gr_chr[k] )
		data = genotypeToSnpMatrix(res)

		# Convert to numeric
		X = as(data$genotypes, "numeric")

		identical(rownames(X), info$sample)

		# get training set
		idx_train = info$pop != df_grid$pop.train[i]

		# Get SNPs with non-zero variance in both training and testing
		X_train = X[idx_train,]
		X_test = X[!idx_train,]

		# pass MAF filter in both sets
		keep = (apply(X_train, 2, maf) > 0.05) & (apply(X_test, 2, maf) > 0.05)

		# learn transformation
		ecl = eclairs( X_train[,keep], compute="correlation")

		# select lambda based on method
		lambda = switch( df_grid$method[i], 
			eb = ecl$lambda, 
			"0.01" = 0.01,
			"LW" = CovEst.2003LW( scale(X_train[,keep]) )$delta,
			"Touloumis" = shrinkcovmat.identity(scale(X_train[,keep]))$lambdahat,
			"Schafer" = estimate.lambda(scale(X_train[,keep]), verbose=FALSE)  )

    lambda = min(1, max(0, lambda))

		# transform testing data
		X_test_white = decorrelate(X_test[,keep], ecl, lambda=lambda)

		rMSE_baseline = normCov(cora(X_test[,keep]))

		rMSE = normCov(cora(X_test_white))

		# get rMSE
		data.frame( df_grid[i,], gr_chr[k], nsnps = ncol(X), lambda, rMSE, rMSE_baseline)
	})
	do.call(rbind, df)
})
df = do.call(rbind, df)


ggplot(df, aes(method, rMSE/rMSE_baseline)) + 
	geom_boxplot() +
	theme_classic() +
	theme(aspect.ratio=1)



C1 = cora(X_train[,keep])
C2 = cora(X_test[,keep])

cor(C1[lower.tri(C1)], C2[lower.tri(C2)])

# plot(C1[lower.tri(C1)], C2[lower.tri(C2)])


df_lambda = lapply(seq(1e-4, 1-1e-4, length.out=100), function(lambda){

	X_test_white = decorrelate(X_test[,keep], ecl, lambda=lambda)

	rMSE = normCov(cora(X_test_white))

	data.frame(lambda, rMSE)
})
df_lambda = do.call(rbind, df_lambda)


df_lambda_est = data.frame(		eb = ecl$lambda, 
			"0.01" = 0.01,
			# "LW" = CovEst.2003LW( scale(X_train[,keep]) )$delta,
			"Touloumis" = shrinkcovmat.identity(scale(X_train[,keep]))$lambdahat,
			"Schafer" = estimate.lambda(scale(X_train[,keep]), verbose=FALSE)  )


# add lines showing lambda estimates
fig = ggplot(df_lambda, aes(lambda, rMSE)) +
	geom_point() +
	theme_classic() +
	theme(aspect.ratio=1)
